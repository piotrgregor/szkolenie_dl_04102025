{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# Operacje na tensorach\n",
    "Ta sekcja obejmuje:\n",
    "* Indeksowanie i wycinanie\n",
    "* Zmianę kształtu tensorów (widoki tensorów)\n",
    "* Arytmetykę tensorów i operacje podstawowe\n",
    "* Iloczyny skalarne\n",
    "* Mnożenie macierzy\n",
    "* Dodatkowe, bardziej zaawansowane operacje\n",
    "\n",
    "## Wykonaj standardowe importy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T16:39:20.054580Z",
     "start_time": "2025-09-30T16:39:19.250402Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indeksowanie i wycinanie\n",
    "Wyodrębnianie konkretnych wartości z tensora działa tak samo jak w tablicach NumPy<br>\n",
    "<img src='../_img/arrayslicing.png' width=\"500\" style=\"display: inline-block\"><br><br>\n",
    "Źródło obrazu: https://scipy-lectures.org/_images/numpy_indexing.png\n",
    "\n",
    "Na początek utwórzmy taki tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T16:53:10.494040Z",
     "start_time": "2025-09-30T16:53:10.483928Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3,  4,  5],\n",
      "        [10, 11, 12, 13, 14, 15],\n",
      "        [20, 21, 22, 23, 24, 25],\n",
      "        [30, 31, 32, 33, 34, 35],\n",
      "        [40, 41, 42, 43, 44, 45],\n",
      "        [50, 51, 52, 53, 54, 55]])\n"
     ]
    }
   ],
   "source": [
    "# liczby w pierwszym wierszu\n",
    "row0 = torch.arange(6)  # [0,1,2,3,4,5]\n",
    "\n",
    "# wykorzystujemy broadcasting - reshape robi nam z wiersza kolumne z 6cioma wierszami.\n",
    "x = row0 + row0.reshape(6, 1) * 10\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aleternatywie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T16:50:17.928147Z",
     "start_time": "2025-09-30T16:50:17.916270Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3,  4,  5],\n",
      "        [10, 11, 12, 13, 14, 15],\n",
      "        [20, 21, 22, 23, 24, 25],\n",
      "        [30, 31, 32, 33, 34, 35],\n",
      "        [40, 41, 42, 43, 44, 45],\n",
      "        [50, 51, 52, 53, 54, 55]])\n"
     ]
    }
   ],
   "source": [
    "print(row0 + row0.unsqueeze(1) * 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`unsqueeze(1)` dodaje nowy wymiar (dimension) do tensora na pozycji 1.\n",
    "\n",
    "W tym przypadku:\n",
    "- `offsets` ma kształt `[6]` (wektor 1D): `[0, 10, 20, 30, 40, 50]`\n",
    "- `offsets.unsqueeze(1)` ma kształt `[6, 1]` (macierz kolumnowa):\n",
    "```\n",
    "[[ 0],\n",
    " [10],\n",
    " [20],\n",
    " [30],\n",
    " [40],\n",
    " [50]]\n",
    "```\n",
    "\n",
    "\n",
    "To jest przydatne do operacji broadcasting - pozwala na dodawanie tego tensora kolumnowego do wektora wierszowego `row0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T16:51:42.815075Z",
     "start_time": "2025-09-30T16:51:42.797244Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(row0.reshape(6,1) == row0.unsqueeze(1)).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../_img/arrayslicing.png' width=\"500\" style=\"display: inline-block\"><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T16:56:06.098029Z",
     "start_time": "2025-09-30T16:56:06.086397Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 4])\n",
      "tensor([[44, 45],\n",
      "        [54, 55]])\n",
      "tensor([ 2, 12, 22, 32, 42, 52])\n",
      "tensor([[20, 22, 24],\n",
      "        [40, 42, 44]])\n"
     ]
    }
   ],
   "source": [
    "print(x[0, 3:5])\n",
    "print(x[4:, 4:])\n",
    "print(x[:,2])\n",
    "print(x[2::2,::2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zmienianie kształtu tensorów przy użyciu <tt>.view()</tt>\n",
    "<a href='https://pytorch.org/docs/master/tensors.html#torch.Tensor.view'><strong><tt>view()</tt></strong></a> oraz <a href='https://pytorch.org/docs/master/torch.html#torch.reshape'><strong><tt>reshape()</tt></strong></a> w zasadzie robią to samo, zwracając tensor o zmienionym kształcie bez modyfikowania oryginału.<br>\n",
    "Dobrą dyskusję na temat różnic znajdziesz <a href='https://stackoverflow.com/questions/49643225/whats-the-difference-between-reshape-and-view-in-pytorch'>tutaj</a>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T17:48:30.364253Z",
     "start_time": "2025-09-30T17:48:30.292598Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(10)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T17:48:30.704900Z",
     "start_time": "2025-09-30T17:48:30.686456Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3, 4],\n",
       "        [5, 6, 7, 8, 9]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(2,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T17:48:36.234877Z",
     "start_time": "2025-09-30T17:48:36.232109Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [2, 3],\n",
       "        [4, 5],\n",
       "        [6, 7],\n",
       "        [8, 9]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(5,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T17:48:36.408700Z",
     "start_time": "2025-09-30T17:48:36.406149Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x pozostaje bez zmian\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Widoki odzwierciedlają aktualne dane\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T17:48:36.447697Z",
     "start_time": "2025-09-30T17:48:36.440764Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[234,   1,   2,   3,   4],\n",
      "        [  5,   6,   7,   8,   9]])\n"
     ]
    }
   ],
   "source": [
    "z = x.view(2,5)\n",
    "x[0]=234\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Widoki mogą samodzielnie wywnioskować rozmiar\n",
    "Przekazując <tt>-1</tt> sprawiamy, że PyTorch wyliczy właściwą wartość na podstawie danego tensora.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T17:48:36.460220Z",
     "start_time": "2025-09-30T17:48:36.457160Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[234,   1,   2,   3,   4],\n",
       "        [  5,   6,   7,   8,   9]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(2,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T17:48:36.514458Z",
     "start_time": "2025-09-30T17:48:36.511551Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[234,   1,   2,   3,   4],\n",
       "        [  5,   6,   7,   8,   9]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(-1,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Przyjmij kształt innego tensora dzięki <tt>.view_as()</tt>\n",
    "<a href='https://pytorch.org/docs/master/tensors.html#torch.Tensor.view_as'><strong><tt>view_as(input)</tt></strong></a> działa tylko dla tensorów o tej samej liczbie elementów.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T17:48:36.650703Z",
     "start_time": "2025-09-30T17:48:36.647392Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[234,   1,   2,   3,   4],\n",
       "        [  5,   6,   7,   8,   9]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view_as(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arytmetyka tensorów\n",
    "Dodawanie tensorów można wykonać na kilka sposobów, w zależności od oczekiwanego wyniku.<br>\n",
    "\n",
    "Jako proste wyrażenie:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T17:48:38.136285Z",
     "start_time": "2025-09-30T17:48:38.106921Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 7., 9.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1,2,3], dtype=torch.float)\n",
    "b = torch.tensor([4,5,6], dtype=torch.float)\n",
    "print(a + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jako argumenty przekazane do operacji PyTorch:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T17:48:39.946942Z",
     "start_time": "2025-09-30T17:48:39.940547Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 7., 9.])\n"
     ]
    }
   ],
   "source": [
    "print(torch.add(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przekazując tensor wyjściowy jako argument:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T17:48:40.857150Z",
     "start_time": "2025-09-30T17:48:40.848383Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 7., 9.])\n"
     ]
    }
   ],
   "source": [
    "result = torch.empty(3)\n",
    "torch.add(a, b, out=result)  # to samo co result=torch.add(a,b)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modyfikacja tensora w miejscu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T17:48:42.522523Z",
     "start_time": "2025-09-30T17:48:42.519132Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 7., 9.])\n"
     ]
    }
   ],
   "source": [
    "a.add_(b)  # to samo co a=torch.add(a,b)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><strong>UWAGA:</strong> Każda operacja, która zmienia tensor w miejscu, ma na końcu znak podkreślenia _.<br>\n",
    "W powyższym przykładzie: <tt>a.add_(b)</tt> zmieniło tensor <tt>a</tt>.</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"display: inline-block\">\n",
    "<caption style=\"text-align: center\"><strong>Operacje arytmetyczne</strong></caption>\n",
    "<tr><th>OPERACJA</th><th>FUNKCJA</th><th>OPIS</th></tr>\n",
    "<tr><td>a + b</td><td>a.add(b)</td><td>dodawanie element po elemencie</td></tr>\n",
    "<tr><td>a - b</td><td>a.sub(b)</td><td>odejmowanie</td></tr>\n",
    "<tr><td>a * b</td><td>a.mul(b)</td><td>mnożenie</td></tr>\n",
    "<tr><td>a / b</td><td>a.div(b)</td><td>dzielenie</td></tr>\n",
    "<tr><td>a % b</td><td>a.fmod(b)</td><td>reszta z dzielenia</td></tr>\n",
    "<tr><td>a<sup>b</sup></td><td>a.pow(b)</td><td>potęgowanie</td></tr>\n",
    "<tr><td>&nbsp;</td><td></td><td></td></tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"display: inline-block\">\n",
    "<caption style=\"text-align: center\"><strong>Operacje monominalne</strong></caption>\n",
    "<tr><th>OPERACJA</th><th>FUNKCJA</th><th>OPIS</th></tr>\n",
    "<tr><td>|a|</td><td>torch.abs(a)</td><td>wartość bezwzględna</td></tr>\n",
    "<tr><td>1/a</td><td>torch.reciprocal(a)</td><td>odwrotność</td></tr>\n",
    "<tr><td>$\\sqrt{a}$</td><td>torch.sqrt(a)</td><td>pierwiastek kwadratowy</td></tr>\n",
    "<tr><td>log(a)</td><td>torch.log(a)</td><td>logarytm naturalny</td></tr>\n",
    "<tr><td>e<sup>a</sup></td><td>torch.exp(a)</td><td>funkcja wykładnicza</td></tr>\n",
    "<tr><td>12.34  ==>  12.</td><td>torch.trunc(a)</td><td>część całkowita</td></tr>\n",
    "<tr><td>12.34  ==>  0.34</td><td>torch.frac(a)</td><td>część ułamkowa</td></tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"display: inline-block\">\n",
    "<caption style=\"text-align: center\"><strong>Trygonometria</strong></caption>\n",
    "<tr><th>OPERACJA</th><th>FUNKCJA</th><th>OPIS</th></tr>\n",
    "<tr><td>sin(a)</td><td>torch.sin(a)</td><td>sinus</td></tr>\n",
    "<tr><td>cos(a)</td><td>torch.cos(a)</td><td>cosinus</td></tr>\n",
    "<tr><td>tan(a)</td><td>torch.tan(a)</td><td>tangens</td></tr>\n",
    "<tr><td>arcsin(a)</td><td>torch.asin(a)</td><td>arcus sinus</td></tr>\n",
    "<tr><td>arccos(a)</td><td>torch.acos(a)</td><td>arcus cosinus</td></tr>\n",
    "<tr><td>arctan(a)</td><td>torch.atan(a)</td><td>arcus tangens</td></tr>\n",
    "<tr><td>sinh(a)</td><td>torch.sinh(a)</td><td>sinus hiperboliczny</td></tr>\n",
    "<tr><td>cosh(a)</td><td>torch.cosh(a)</td><td>cosinus hiperboliczny</td></tr>\n",
    "<tr><td>tanh(a)</td><td>torch.tanh(a)</td><td>tangens hiperboliczny</td></tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"display: inline-block\">\n",
    "<caption style=\"text-align: center\"><strong>Statystyki opisowe</strong></caption>\n",
    "<tr><th>OPERACJA</th><th>FUNKCJA</th><th>OPIS</th></tr>\n",
    "<tr><td>$\\sum a$</td><td>torch.sum(a)</td><td>suma</td></tr>\n",
    "<tr><td>$\bar a$</td><td>torch.mean(a)</td><td>średnia</td></tr>\n",
    "<tr><td>a<sub>max</sub></td><td>torch.max(a)</td><td>maksimum</td></tr>\n",
    "<tr><td>a<sub>min</sub></td><td>torch.min(a)</td><td>minimum</td></tr>\n",
    "<tr><td colspan=\"3\">torch.max(a,b) zwraca tensor rozmiaru a<br>zawierający wartości maksymalne element po elemencie między a i b</td></tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><strong>UWAGA:</strong> Większość operacji arytmetycznych wymaga wartości zmiennoprzecinkowych. Te, które działają na liczbach całkowitych, zwracają tensory całkowitoliczbowe.<br>\n",
    "Na przykład <tt>torch.div(a,b)</tt> dla typów całkowitych wykonuje dzielenie całkowite (ucięcie części ułamkowej), a dla floatów – klasyczne dzielenie.</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Użyj poniższej przestrzeni, aby poeksperymentować z różnymi operacjami\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T17:54:53.355282Z",
     "start_time": "2025-09-30T17:54:53.341763Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(21.)\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1,2,3], dtype=torch.float)\n",
    "b = torch.tensor([4,5,6], dtype=torch.float)\n",
    "print(torch.add(a,b).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T17:48:56.596915Z",
     "start_time": "2025-09-30T17:48:56.594805Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T17:48:57.960944Z",
     "start_time": "2025-09-30T17:48:57.959115Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iloczyny skalarne\n",
    "<a href='https://en.wikipedia.org/wiki/Dot_product'>Iloczyn skalarny</a> to suma iloczynów odpowiadających sobie elementów dwóch tensorów 1D. Jeśli tensory są wektorami, iloczyn skalarny ma postać:<br>\n",
    "\n",
    "$\\begin{bmatrix} a & b & c \\end{bmatrix} \\;\\cdot\\; \\begin{bmatrix} d & e & f \\end{bmatrix} = ad + be + cf$\n",
    "\n",
    "Jeśli tensor zawiera wektor kolumnowy, wynik to suma elementów z pomnożonych macierzy. Przykładowo:<br>\n",
    "$\\begin{bmatrix} a & b & c \\end{bmatrix} \\;\\cdot\\; \\begin{bmatrix} d \\ e \\ f \\end{bmatrix} = ad + be + cf$<br><br>\n",
    "\n",
    "Iloczyn skalarny można obliczyć funkcją <a href='https://pytorch.org/docs/stable/torch.html#torch.dot'><strong><tt>torch.dot(a,b)</tt></strong></a> lub zapisami `a.dot(b)` czy `b.dot(a)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T17:49:58.382206Z",
     "start_time": "2025-09-30T17:49:58.369280Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4., 10., 18.])\n",
      "\n",
      "tensor(32.)\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1,2,3], dtype=torch.float)\n",
    "b = torch.tensor([4,5,6], dtype=torch.float)\n",
    "print(a.mul(b)) # dla porównania\n",
    "print()\n",
    "print(a.dot(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><strong>UWAGA:</strong> Istnieje niewielka różnica między <tt>torch.dot()</tt> a <tt>numpy.dot()</tt>. <tt>torch.dot()</tt> przyjmuje wyłącznie argumenty 1D i zwraca iloczyn skalarny, natomiast <tt>numpy.dot()</tt> obsługuje także argumenty 2D i wykonuje mnożenie macierzy. Mnożenie macierzy pokazujemy poniżej.</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mnożenie macierzy\n",
    "Dwuwymiarowe <a href='https://en.wikipedia.org/wiki/Matrix_multiplication'>mnożenie macierzy</a> jest możliwe, gdy liczba kolumn tensora <strong><tt>A</tt></strong> odpowiada liczbie wierszy tensora <strong><tt>B</tt></strong>. W takim przypadku iloczyn tensora <strong><tt>A</tt></strong> o rozmiarze $(x,y)$ i tensora <strong><tt>B</tt></strong> o rozmiarze $(y,z)$ daje tensor o rozmiarze $(x,z)$.\n",
    "<div>\n",
    "<div align=\"left\"><img src='../_img/Matrix_multiplication_diagram.png' align=\"left\"><br><br>\n",
    "\n",
    "$\\begin{bmatrix} a & b & c \\\n",
    "d & e & f \\end{bmatrix} \\;\times\\; \\begin{bmatrix} m & n \\ p & q \\ r & s \\end{bmatrix} = \\begin{bmatrix} (am+bp+cr) & (an+bq+cs) \\\n",
    "(dm+ep+fr) & (dn+eq+fs) \\end{bmatrix}$</div></div>\n",
    "\n",
    "<div style=\"clear:both\">Źródło obrazu: <a href='https://commons.wikimedia.org/wiki/File:Matrix_multiplication_diagram_2.svg'>https://commons.wikimedia.org/wiki/File:Matrix_multiplication_diagram_2.svg</a></div>\n",
    "\n",
    "Mnożenie macierzy można obliczyć funkcją <a href='https://pytorch.org/docs/stable/torch.html#torch.mm'><strong><tt>torch.mm(a,b)</tt></strong></a> lub zapisami `a.mm(b)` albo `a @ b`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T17:50:37.164197Z",
     "start_time": "2025-09-30T17:50:37.147102Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:  torch.Size([2, 3])\n",
      "b:  torch.Size([3, 2])\n",
      "a x b:  torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[0,2,4],[1,3,5]], dtype=torch.float)\n",
    "b = torch.tensor([[6,7],[8,9],[10,11]], dtype=torch.float)\n",
    "\n",
    "print('a: ',a.size())\n",
    "print('b: ',b.size())\n",
    "print('a x b: ',torch.mm(a,b).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T17:50:37.796342Z",
     "start_time": "2025-09-30T17:50:37.791569Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[56., 62.],\n",
      "        [80., 89.]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.mm(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T17:50:38.310344Z",
     "start_time": "2025-09-30T17:50:38.307013Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[56., 62.],\n",
      "        [80., 89.]])\n"
     ]
    }
   ],
   "source": [
    "print(a.mm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T17:50:38.927746Z",
     "start_time": "2025-09-30T17:50:38.923304Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[56., 62.],\n",
      "        [80., 89.]])\n"
     ]
    }
   ],
   "source": [
    "print(a @ b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mnożenie macierzy z broadcastingiem\n",
    "Mnożenie macierzy z <a href='https://pytorch.org/docs/stable/notes/broadcasting.html#broadcasting-semantics'>broadcastingiem</a> można obliczyć przy użyciu <a href='https://pytorch.org/docs/stable/torch.html#torch.matmul'><strong><tt>torch.matmul(a,b)</tt></strong></a> lub zapisów `a.matmul(b)` czy `a @ b`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T17:50:40.863428Z",
     "start_time": "2025-09-30T17:50:40.854265Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.randn(2, 3, 4)\n",
    "t2 = torch.randn(4, 5)\n",
    "\n",
    "print(torch.matmul(t1, t2).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ten sam zabieg wywołuje jednak <tt><strong>RuntimeError</strong></tt> przy użyciu <tt>torch.mm()</tt>:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T17:50:41.972123Z",
     "start_time": "2025-09-30T17:50:41.742051Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "self must be a matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt2\u001b[49m\u001b[43m)\u001b[49m.size())\n",
      "\u001b[31mRuntimeError\u001b[39m: self must be a matrix"
     ]
    }
   ],
   "source": [
    "print(torch.mm(t1, t2).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Operacje zaawansowane\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Norma L2 (euklidesowa)\n",
    "Zobacz <a href='https://pytorch.org/docs/stable/torch.html#torch.norm'><strong><tt>torch.norm()</tt></strong></a>\n",
    "\n",
    "<a href='https://en.wikipedia.org/wiki/Norm_(mathematics)#Euclidean_norm'>Norma euklidesowa</a> daje normę wektora $x$, dla $x=(x_1,x_2,...,x_n)$.\n",
    "Obliczamy ją jako\n",
    "\n",
    "${\\displaystyle \\left\\|\\boldsymbol{x}\\right\\|_{2} := \\sqrt{x_{1}^{2} + \\cdots + x_{n}^{2}}}$\n",
    "\n",
    "\n",
    "Po zastosowaniu do macierzy <tt>torch.norm()</tt> zwraca domyślnie <a href='https://en.wikipedia.org/wiki/Matrix_norm#Frobenius_norm'>normę Frobeniusa</a>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T17:54:14.368646Z",
     "start_time": "2025-09-30T17:54:14.297818Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17.)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([2.,5.,8.,14.])\n",
    "x.norm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Liczba elementów\n",
    "\n",
    "Zobacz <a href='https://pytorch.org/docs/stable/torch.html#torch.numel'><strong><tt>torch.numel()</tt></strong></a>\n",
    "\n",
    "Zwraca liczbę elementów w tensorze.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T17:54:21.696442Z",
     "start_time": "2025-09-30T17:54:21.681648Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(3,7)\n",
    "x.numel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Może być to przydatne w obliczeniach, takich jak błąd średniokwadratowy (MSE):<br>\n",
    "<tt>\n",
    "def mse(t1, t2):<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;diff = t1 - t2<br>\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;return torch.sum(diff * diff) / diff<strong>.numel()</strong></tt>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Świetna robota!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
