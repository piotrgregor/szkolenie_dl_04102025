{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“˜ Wczytywanie danych w TensorFlow i Keras\n",
    "\n",
    "## 1. Wczytywanie CSV wprost do `tf.data.Dataset`\n",
    "\n",
    "TensorFlow ma wbudowanÄ… funkcjÄ™ `tf.data.experimental.make_csv_dataset`, ktÃ³ra zamienia plik CSV w strumieÅ„ danych (dataset).\n",
    "\n",
    "PrzykÅ‚ad dla pliku `Data/iris.csv`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cechy: OrderedDict({'sepal length (cm)': <tf.Tensor: shape=(16,), dtype=float32, numpy=\n",
      "array([5.6, 6.8, 5.8, 6.6, 5.4, 5.7, 7.6, 6.3, 6.3, 6.1, 5.4, 5. , 5.6,\n",
      "       6.1, 5.6, 4.4], dtype=float32)>, 'sepal width (cm)': <tf.Tensor: shape=(16,), dtype=float32, numpy=\n",
      "array([2.8, 3.2, 2.7, 2.9, 3.4, 2.9, 3. , 2.7, 2.5, 2.9, 3.7, 3.2, 3. ,\n",
      "       2.8, 2.9, 3. ], dtype=float32)>, 'petal length (cm)': <tf.Tensor: shape=(16,), dtype=float32, numpy=\n",
      "array([4.9, 5.9, 4.1, 4.6, 1.7, 4.2, 6.6, 4.9, 5. , 4.7, 1.5, 1.2, 4.5,\n",
      "       4. , 3.6, 1.3], dtype=float32)>, 'petal width (cm)': <tf.Tensor: shape=(16,), dtype=float32, numpy=\n",
      "array([2. , 2.3, 1. , 1.3, 0.2, 1.3, 2.1, 1.8, 1.9, 1.4, 0.2, 0.2, 1.5,\n",
      "       1.3, 1.3, 0.2], dtype=float32)>})\n",
      "Etykiety: tf.Tensor([2. 2. 1. 1. 0. 1. 2. 2. 2. 1. 0. 0. 1. 1. 1. 0.], shape=(16,), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-02 18:56:12.507308: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# ÅšcieÅ¼ka do danych\n",
    "file_path = \"../Data/iris.csv\"\n",
    "\n",
    "# Wczytanie CSV jako dataset\n",
    "dataset = tf.data.experimental.make_csv_dataset(\n",
    "    file_path,\n",
    "    batch_size=16,       # rozmiar batcha\n",
    "    label_name=\"target\", # kolumna etykiety\n",
    "    num_epochs=1,        # ile razy przejÅ›Ä‡ przez dane\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# PodglÄ…d batcha\n",
    "for features, label in dataset.take(1):\n",
    "    print(\"Cechy:\", features)\n",
    "    print(\"Etykiety:\", label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ‘‰ Zalety: dziaÅ‚a dobrze z duÅ¼ymi plikami, dane wczytywane sÄ… leniwie (strumieniowo).\n",
    "ðŸ‘‰ Uwaga: `species` musi byÄ‡ kolumnÄ… w CSV.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Wczytanie CSV do Pandas + konwersja do TensorFlow\n",
    "\n",
    "CzÄ™sto proÅ›ciej jest najpierw wczytaÄ‡ dane Pandasem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0     0.0  \n",
       "1     0.0  \n",
       "2     0.0  \n",
       "3     0.0  \n",
       "4     0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# Wczytanie Pandasem\n",
    "df = pd.read_csv(\"../Data/iris.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4) (150,)\n"
     ]
    }
   ],
   "source": [
    "# Oddzielenie X i y\n",
    "X = df.drop(\"target\", axis=1).values\n",
    "y = df[\"target\"].astype(\"category\").cat.codes.values  # zamiana na liczby\n",
    "\n",
    "# Konwersja do tensora\n",
    "X_tensor = tf.convert_to_tensor(X, dtype=tf.float32)\n",
    "y_tensor = tf.convert_to_tensor(y, dtype=tf.int32)\n",
    "\n",
    "print(X_tensor.shape, y_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ‘‰ Ten sposÃ³b daje wiÄ™kszÄ… kontrolÄ™ nad preprocessingiem (np. normalizacja, one-hot encoding).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. UÅ¼ycie Keras `keras.utils` â€“ np. `image_dataset_from_directory`, `text_dataset_from_directory`, `timeseries_dataset_from_array`\n",
    "\n",
    "Dla CSV nie ma gotowej funkcji, ale moÅ¼na Å‚atwo zamieniÄ‡ Pandas â†’ NumPy â†’ Keras `Dataset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X batch: [[[5.1 3.5 1.4 0.2]]\n",
      "\n",
      " [[4.9 3.  1.4 0.2]]\n",
      "\n",
      " [[4.7 3.2 1.3 0.2]]\n",
      "\n",
      " [[4.6 3.1 1.5 0.2]]\n",
      "\n",
      " [[5.  3.6 1.4 0.2]]\n",
      "\n",
      " [[5.4 3.9 1.7 0.4]]\n",
      "\n",
      " [[4.6 3.4 1.4 0.3]]\n",
      "\n",
      " [[5.  3.4 1.5 0.2]]\n",
      "\n",
      " [[4.4 2.9 1.4 0.2]]\n",
      "\n",
      " [[4.9 3.1 1.5 0.1]]\n",
      "\n",
      " [[5.4 3.7 1.5 0.2]]\n",
      "\n",
      " [[4.8 3.4 1.6 0.2]]\n",
      "\n",
      " [[4.8 3.  1.4 0.1]]\n",
      "\n",
      " [[4.3 3.  1.1 0.1]]\n",
      "\n",
      " [[5.8 4.  1.2 0.2]]\n",
      "\n",
      " [[5.7 4.4 1.5 0.4]]]\n",
      "y batch: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-02 18:56:12.591142: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "\n",
    "# Wczytaj CSV\n",
    "df = pd.read_csv(\"../Data/iris.csv\")\n",
    "\n",
    "X = df.drop(\"target\", axis=1).values\n",
    "y = df[\"target\"].astype(\"category\").cat.codes.values\n",
    "\n",
    "# Konwersja do datasetu keras\n",
    "dataset = keras.utils.timeseries_dataset_from_array(\n",
    "    data=X,\n",
    "    targets=y,\n",
    "    sequence_length=1,   # tu akurat nie czasowe, wiÄ™c 1\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "for batch_x, batch_y in dataset.take(1):\n",
    "    print(\"X batch:\", batch_x.numpy())\n",
    "    print(\"y batch:\", batch_y.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“š Zbiory danych w `keras.datasets`\n",
    "\n",
    "W pakiecie znajdziesz m.in.:\n",
    "\n",
    "* **MNIST** â€“ rÄ™cznie pisane cyfry (0â€“9, grayscale, 28Ã—28)\n",
    "* **Fashion-MNIST** â€“ ubrania zamiast cyfr (rÃ³wnieÅ¼ 28Ã—28)\n",
    "* **CIFAR-10 / CIFAR-100** â€“ kolorowe obrazki (32Ã—32, 10 lub 100 klas)\n",
    "* **IMDB** â€“ recenzje filmÃ³w (do NLP, sentyment analysis)\n",
    "* **Reuters** â€“ krÃ³tkie teksty wiadomoÅ›ci (kategoryzacja tekstu)\n",
    "* **Boston Housing** â€“ ceny mieszkaÅ„ w Bostonie (regresja)\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ”¹ PrzykÅ‚ad: MNIST (klasyczny dataset obrazÃ³w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (60000, 28, 28)\n",
      "y_train shape: (60000,)\n"
     ]
    }
   ],
   "source": [
    "# Wczytanie danych\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "\n",
    "# Normalizacja (opcjonalnie)\n",
    "X_train = X_train.astype(\"float32\") / 255.0\n",
    "X_test = X_test.astype(\"float32\") / 255.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### ðŸ”¹ PrzykÅ‚ad: CIFAR-10 (kolorowe obrazki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obrazki: (50000, 32, 32, 3)\n",
      "Etykiety: (50000, 1)\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "print(\"Obrazki:\", X_train.shape)\n",
    "print(\"Etykiety:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ðŸ”¹ PrzykÅ‚ad: IMDB (analiza sentymentu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba prÃ³bek w train: 25000\n",
      "Pierwsza prÃ³bka (zakodowana): [1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65]\n",
      "Etykieta: 1\n"
     ]
    }
   ],
   "source": [
    "# Ograniczamy sÅ‚ownik do 10k najczÄ™stszych sÅ‚Ã³w\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.imdb.load_data(num_words=10000)\n",
    "\n",
    "print(\"Liczba prÃ³bek w train:\", len(X_train))\n",
    "print(\"Pierwsza prÃ³bka (zakodowana):\", X_train[0][:10])\n",
    "print(\"Etykieta:\", y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ‘‰ W tym przypadku dane sÄ… juÅ¼ ztokenizowane â€“ jako sekwencje ID sÅ‚Ã³w.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# ðŸš€ Podsumowanie\n",
    "\n",
    "* **TensorFlow** â†’ uÅ¼ywamy `tf.data.experimental.make_csv_dataset` do CSV.\n",
    "* **Pandas + TensorFlow** â†’ wiÄ™ksza kontrola nad preprocessingiem, Å‚atwoÅ›Ä‡ uÅ¼ycia.\n",
    "* **Keras** â†’ dane moÅ¼na przygotowaÄ‡ w NumPy/Pandas i przekazaÄ‡ do `model.fit()`.\n",
    "* **Zaawansowane** â†’ `tf.data.Dataset` daje najwiÄ™kszÄ… elastycznoÅ›Ä‡ (batching, shuffling, mapowanie transformacji).\n",
    "\n",
    "---\n",
    "\n",
    "ðŸ‘‰ Chcesz Å¼ebym zrobiÅ‚ Ci gotowy **notebook Jupyter** z przykÅ‚adami na `iris.csv` (Å‚adowanie rÃ³Å¼nymi metodami + prosty model Keras), Å¼ebyÅ› mÃ³gÅ‚ od razu uÅ¼yÄ‡ na szkoleniu?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
